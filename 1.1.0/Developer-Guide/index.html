<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Developer Guide - SQL DS Cache</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = './sql-ds-cache/';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Developer Guide", url: "#developer-guide", children: [
              {title: "Building", url: "#building" },
              {title: "Enabling NUMA binding for PMem in Spark", url: "#enabling-numa-binding-for-pmem-in-spark" },
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-125166209-1', 'oap-project.github.io/sql-ds-cache');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Developer Guide</strong></h1>
    <hr>
    <h1 id="developer-guide">Developer Guide</h1>
<p>This document is a supplement to the whole <a href="../OAP-Developer-Guide/">OAP Developer Guide</a> for SQL Index and Data Source Cache.
After following that document, you can continue more details for SQL Index and Data Source Cache.</p>
<ul>
<li><a href="#Building">Building</a></li>
<li><a href="#enabling-numa-binding-for-pmem-in-spark">Enabling NUMA binding for Intel® Optane™ DC Persistent Memory in Spark</a></li>
</ul>
<h2 id="building">Building</h2>
<h3 id="building-sql-ds-cache">Building SQL DS  Cache</h3>
<p>Building with <a href="http://maven.apache.org/">Apache Maven*</a>.</p>
<p>Before building, install PMem-Common locally:</p>
<pre><code>git clone -b &lt;tag-version&gt; https://github.com/oap-project/pmem-common.git
cd pmem-common
mvn clean install -DskipTests
</code></pre>

<p>Build the SQL DS Cache package:</p>
<pre><code>git clone -b &lt;tag-version&gt; https://github.com/oap-project/sql-ds-cache.git
cd sql-ds-cache
mvn clean -DskipTests package
</code></pre>

<h3 id="running-tests">Running Tests</h3>
<p>Run all the tests:</p>
<pre><code>mvn clean test
</code></pre>

<p>Run a specific test suite, for example <code>OapDDLSuite</code>:</p>
<pre><code>mvn -DwildcardSuites=org.apache.spark.sql.execution.datasources.oap.OapDDLSuite test
</code></pre>

<p><strong>NOTE</strong>: Log level of unit tests currently default to ERROR, please override oap-cache/oap/src/test/resources/log4j.properties if needed.</p>
<h3 id="building-with-intel-optanetm-dc-persistent-memory-module">Building with Intel® Optane™ DC Persistent Memory Module</h3>
<h4 id="prerequisites-for-building-with-pmem-support">Prerequisites for building with PMem support</h4>
<p>Install the required packages on the build system:</p>
<ul>
<li><a href="https://help.directadmin.com/item.php?id=494">cmake</a></li>
<li><a href="https://github.com/memkind/memkind/tree/v1.10.1">memkind</a></li>
<li><a href="https://github.com/pmem/vmemcache">vmemcache</a></li>
<li><a href="http://arrow.apache.org/blog/2017/08/08/plasma-in-memory-object-store/">Plasma</a></li>
</ul>
<h4 id="memkind-installation">memkind installation</h4>
<p>The memkind library depends on <code>libnuma</code> at the runtime, so it must already exist in the worker node system. Build the latest memkind lib from source:</p>
<pre><code>git clone -b v1.10.1 https://github.com/memkind/memkind
cd memkind
./autogen.sh
./configure
make
make install
</code></pre>

<h4 id="vmemcache-installation">vmemcache installation</h4>
<p>To build vmemcache library from source, you can (for RPM-based linux as example):</p>
<pre><code>git clone https://github.com/pmem/vmemcache
cd vmemcache
mkdir build
cd build
cmake .. -DCMAKE_INSTALL_PREFIX=/usr -DCPACK_GENERATOR=rpm
make package
sudo rpm -i libvmemcache*.rpm
</code></pre>

<h4 id="plasma-installation">Plasma installation</h4>
<p>To use optimized Plasma cache with OAP, you need following components:  </p>
<p>(1) <code>libarrow.so</code>, <code>libplasma.so</code>, <code>libplasma_java.so</code>: dynamic libraries, will be used in Plasma client. <br />
   (2) <code>plasma-store-server</code>: executable file, Plasma cache service.<br />
   (3) <code>arrow-plasma-0.17.0.jar</code>: will be used when compile oap and spark runtime also need it. </p>
<ul>
<li><code>.so</code> file and binary file<br />
  Clone code from Intel-arrow repo and run following commands, this will install <code>libplasma.so</code>, <code>libarrow.so</code>, <code>libplasma_java.so</code> and <code>plasma-store-server</code> to your system path(<code>/usr/lib64</code> by default). And if you are using Spark in a cluster environment, you can copy these files to all nodes in your cluster if the OS or distribution are same, otherwise, you need compile it on each node.</li>
</ul>
<pre><code>cd /tmp
git clone https://github.com/Intel-bigdata/arrow.git
cd arrow &amp;&amp; git checkout branch-0.17.0-oap-1.0
cd cpp
mkdir release
cd release
#build libarrow, libplasma, libplasma_java
cmake -DCMAKE_INSTALL_PREFIX=/usr/ -DCMAKE_BUILD_TYPE=Release -DARROW_BUILD_TESTS=on -DARROW_PLASMA_JAVA_CLIENT=on -DARROW_PLASMA=on -DARROW_DEPENDENCY_SOURCE=BUNDLED  ..
make -j$(nproc)
sudo make install -j$(nproc)
</code></pre>

<ul>
<li>arrow-plasma-0.17.0.jar<br />
<code>arrow-plasma-0.17.0.jar</code> is provided in Maven central repo, you can download <a href="https://repo1.maven.org/maven2/com/intel/arrow/arrow-plasma/0.17.0/arrow-plasma-0.17.0.jar">it</a> and copy to <code>$SPARK_HOME/jars</code> dir.</li>
</ul>
<p>Or you can manually install it, run following command, this will install arrow jars to your local maven repo. Besides, you need copy arrow-plasma-0.17.0.jar to <code>$SPARK_HOME/jars/</code> dir, cause this jar is needed when using external cache.</p>
<pre><code>cd /tmp/arrow/java
mvn clean -q  plasma -DskipTests install
</code></pre>

<h4 id="building-the-package">Building the package</h4>
<p>You need to add <code>-Ppersistent-memory</code> to build with PMem support. For <code>noevict</code> cache strategy, you also need to build with <code>-Ppersistent-memory</code> parameter.</p>
<pre><code>cd &lt;path&gt;/pmem-common
mvn clean install -Ppersistent-memory -DskipTests 
cd &lt;path&gt;/sql-ds-cache
mvn clean -DskipTests package
</code></pre>

<p>For vmemcache cache strategy, please build with command:</p>
<pre><code>cd &lt;path&gt;/pmem-common
mvn clean install -Pvmemcache -DskipTests
cd &lt;path&gt;/sql-ds-cache
mvn clean -DskipTests package
</code></pre>

<p>Build with this command to use all of them:</p>
<pre><code>cd &lt;path&gt;/pmem-common
mvn clean install -Ppersistent-memory -Pvmemcache -DskipTests
cd &lt;path&gt;/sql-ds-cache
mvn clean -DskipTests package
</code></pre>

<h2 id="enabling-numa-binding-for-pmem-in-spark">Enabling NUMA binding for PMem in Spark</h2>
<h3 id="rebuilding-spark-packages-with-numa-binding-patch">Rebuilding Spark packages with NUMA binding patch</h3>
<p>When using PMem as a cache medium apply the <a href="https://www.kernel.org/doc/html/v4.18/vm/numa.html">NUMA</a> binding patch <a href="../numa-binding-spark-3.0.0.patch">numa-binding-spark-3.0.0.patch</a> to Spark source code for best performance.</p>
<ol>
<li>
<p>Download src for <a href="https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0.tgz">Spark-3.0.0</a> and clone the src from github.</p>
</li>
<li>
<p>Apply this patch and <a href="https://spark.apache.org/docs/latest/building-spark.html">rebuild</a> the Spark package.</p>
</li>
</ol>
<pre><code>git apply  numa-binding-spark-3.0.0.patch
</code></pre>

<ol>
<li>Add these configuration items to the Spark configuration file $SPARK_HOME/conf/spark-defaults.conf to enable NUMA binding.</li>
</ol>
<pre><code>spark.yarn.numa.enabled true 
</code></pre>

<p><strong>NOTE</strong>: If you are using a customized Spark, you will need to manually resolve the conflicts.</p>
<h6 id="42other-names-and-brands-may-be-claimed-as-the-property-of-others">*Other names and brands may be claimed as the property of others.</h6>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>